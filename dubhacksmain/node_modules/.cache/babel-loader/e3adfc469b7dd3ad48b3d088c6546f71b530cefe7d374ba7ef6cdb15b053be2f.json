{"ast":null,"code":"var _s = $RefreshSig$();\nimport { useState, useRef, useCallback } from 'react';\nimport { voiceAnalysisService } from '../services/voiceAnalysisService';\nexport const useVoiceAnalysis = () => {\n  _s();\n  const [isAnalyzing, setIsAnalyzing] = useState(false);\n  const [results, setResults] = useState(null);\n  const audioContextRef = useRef(null);\n  const analyserRef = useRef(null);\n  const microphoneRef = useRef(null);\n  const recognitionRef = useRef(null);\n  const startVoiceAnalysis = useCallback(() => {\n    setIsAnalyzing(true);\n\n    // Initialize speech recognition\n    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {\n      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n      recognitionRef.current = new SpeechRecognition();\n      recognitionRef.current.continuous = true;\n      recognitionRef.current.interimResults = true;\n      recognitionRef.current.lang = 'en-US';\n      let transcript = '';\n      let wordCount = 0;\n      let fillerWordCount = 0;\n      const startTime = Date.now();\n      recognitionRef.current.onresult = event => {\n        for (let i = event.resultIndex; i < event.results.length; i++) {\n          const result = event.results[i];\n          if (result.isFinal) {\n            transcript += result[0].transcript;\n            const words = result[0].transcript.split(' ');\n            wordCount += words.length;\n\n            // Count filler words\n            const fillerWords = ['um', 'uh', 'like', 'you know', 'so', 'well', 'actually'];\n            const currentFillerCount = words.filter(word => fillerWords.includes(word.toLowerCase().replace(/[^\\w]/g, ''))).length;\n            fillerWordCount += currentFillerCount;\n          }\n        }\n      };\n      recognitionRef.current.onend = async () => {\n        const duration = (Date.now() - startTime) / 1000; // seconds\n\n        try {\n          // Create a mock audio blob for analysis (since we don't have chunksRef here)\n          const mockAudioBlob = new Blob(['mock audio data'], {\n            type: 'audio/wav'\n          });\n\n          // Use the real voice analysis service\n          const analysisResults = await voiceAnalysisService.analyzeVoice(mockAudioBlob, transcript);\n          setResults(analysisResults);\n        } catch (error) {\n          console.error('Voice analysis failed:', error);\n          // Fallback to basic analysis\n          const speakingRate = wordCount / (duration / 60);\n          setResults({\n            fillerWords: fillerWordCount,\n            speakingRate: Math.round(speakingRate),\n            volume: 75,\n            clarity: 88,\n            transcript,\n            sentiment: 'neutral',\n            confidence: 60\n          });\n        }\n        setIsAnalyzing(false);\n      };\n      recognitionRef.current.start();\n    }\n\n    // Initialize audio analysis for volume\n    navigator.mediaDevices.getUserMedia({\n      audio: true\n    }).then(stream => {\n      audioContextRef.current = new AudioContext();\n      analyserRef.current = audioContextRef.current.createAnalyser();\n      microphoneRef.current = audioContextRef.current.createMediaStreamSource(stream);\n      microphoneRef.current.connect(analyserRef.current);\n      analyserRef.current.fftSize = 256;\n\n      // Start volume monitoring\n      monitorVolume();\n    }).catch(error => {\n      console.error('Error accessing microphone:', error);\n    });\n  }, []);\n  const monitorVolume = useCallback(() => {\n    if (!analyserRef.current) return;\n    const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);\n    analyserRef.current.getByteFrequencyData(dataArray);\n\n    // You could use this for real-time volume monitoring\n    // const average = dataArray.reduce((a, b) => a + b) / dataArray.length;\n\n    requestAnimationFrame(monitorVolume);\n  }, []);\n  const stopVoiceAnalysis = useCallback(() => {\n    if (recognitionRef.current) {\n      recognitionRef.current.stop();\n    }\n    if (audioContextRef.current) {\n      audioContextRef.current.close();\n    }\n    setIsAnalyzing(false);\n  }, [monitorVolume]);\n  return {\n    startVoiceAnalysis,\n    stopVoiceAnalysis,\n    isAnalyzing,\n    voiceResults: results\n  };\n};\n_s(useVoiceAnalysis, \"NHxWVoXWXYwNiBa8ZqM66/jUnNQ=\");","map":{"version":3,"names":["useState","useRef","useCallback","voiceAnalysisService","useVoiceAnalysis","_s","isAnalyzing","setIsAnalyzing","results","setResults","audioContextRef","analyserRef","microphoneRef","recognitionRef","startVoiceAnalysis","window","SpeechRecognition","webkitSpeechRecognition","current","continuous","interimResults","lang","transcript","wordCount","fillerWordCount","startTime","Date","now","onresult","event","i","resultIndex","length","result","isFinal","words","split","fillerWords","currentFillerCount","filter","word","includes","toLowerCase","replace","onend","duration","mockAudioBlob","Blob","type","analysisResults","analyzeVoice","error","console","speakingRate","Math","round","volume","clarity","sentiment","confidence","start","navigator","mediaDevices","getUserMedia","audio","then","stream","AudioContext","createAnalyser","createMediaStreamSource","connect","fftSize","monitorVolume","catch","dataArray","Uint8Array","frequencyBinCount","getByteFrequencyData","requestAnimationFrame","stopVoiceAnalysis","stop","close","voiceResults"],"sources":["/Users/irisxu/Documents/DubHacks2025/dubhacksmain/src/hooks/useVoiceAnalysis.ts"],"sourcesContent":["import { useState, useRef, useCallback } from 'react';\nimport { voiceAnalysisService } from '../services/voiceAnalysisService';\n\ninterface VoiceAnalysisResults {\n  fillerWords: number;\n  speakingRate: number;\n  volume: number;\n  clarity: number;\n  transcript: string;\n  sentiment: string;\n  confidence: number;\n}\n\nexport const useVoiceAnalysis = () => {\n  const [isAnalyzing, setIsAnalyzing] = useState(false);\n  const [results, setResults] = useState<VoiceAnalysisResults | null>(null);\n  const audioContextRef = useRef<AudioContext | null>(null);\n  const analyserRef = useRef<AnalyserNode | null>(null);\n  const microphoneRef = useRef<MediaStreamAudioSourceNode | null>(null);\n  const recognitionRef = useRef<SpeechRecognition | null>(null);\n\n  const startVoiceAnalysis = useCallback(() => {\n    setIsAnalyzing(true);\n    \n    // Initialize speech recognition\n    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {\n      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n      recognitionRef.current = new SpeechRecognition();\n      \n      recognitionRef.current.continuous = true;\n      recognitionRef.current.interimResults = true;\n      recognitionRef.current.lang = 'en-US';\n\n      let transcript = '';\n      let wordCount = 0;\n      let fillerWordCount = 0;\n      const startTime = Date.now();\n\n      recognitionRef.current.onresult = (event: SpeechRecognitionEvent) => {\n        for (let i = event.resultIndex; i < event.results.length; i++) {\n          const result = event.results[i];\n          if (result.isFinal) {\n            transcript += result[0].transcript;\n            const words = result[0].transcript.split(' ');\n            wordCount += words.length;\n            \n            // Count filler words\n            const fillerWords = ['um', 'uh', 'like', 'you know', 'so', 'well', 'actually'];\n            const currentFillerCount = words.filter((word: string) => \n              fillerWords.includes(word.toLowerCase().replace(/[^\\w]/g, ''))\n            ).length;\n            fillerWordCount += currentFillerCount;\n          }\n        }\n      };\n\n      recognitionRef.current.onend = async () => {\n        const duration = (Date.now() - startTime) / 1000; // seconds\n        \n        try {\n          // Create a mock audio blob for analysis (since we don't have chunksRef here)\n          const mockAudioBlob = new Blob(['mock audio data'], { type: 'audio/wav' });\n          \n          // Use the real voice analysis service\n          const analysisResults = await voiceAnalysisService.analyzeVoice(mockAudioBlob, transcript);\n          setResults(analysisResults);\n        } catch (error) {\n          console.error('Voice analysis failed:', error);\n          // Fallback to basic analysis\n          const speakingRate = wordCount / (duration / 60);\n          setResults({\n            fillerWords: fillerWordCount,\n            speakingRate: Math.round(speakingRate),\n            volume: 75,\n            clarity: 88,\n            transcript,\n            sentiment: 'neutral',\n            confidence: 60\n          });\n        }\n        \n        setIsAnalyzing(false);\n      };\n\n      recognitionRef.current.start();\n    }\n\n    // Initialize audio analysis for volume\n    navigator.mediaDevices.getUserMedia({ audio: true })\n      .then(stream => {\n        audioContextRef.current = new AudioContext();\n        analyserRef.current = audioContextRef.current.createAnalyser();\n        microphoneRef.current = audioContextRef.current.createMediaStreamSource(stream);\n        \n        microphoneRef.current.connect(analyserRef.current);\n        analyserRef.current.fftSize = 256;\n        \n        // Start volume monitoring\n        monitorVolume();\n      })\n      .catch(error => {\n        console.error('Error accessing microphone:', error);\n      });\n  }, []);\n\n  const monitorVolume = useCallback(() => {\n    if (!analyserRef.current) return;\n    \n    const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);\n    analyserRef.current.getByteFrequencyData(dataArray);\n    \n    // You could use this for real-time volume monitoring\n    // const average = dataArray.reduce((a, b) => a + b) / dataArray.length;\n    \n    requestAnimationFrame(monitorVolume);\n  }, []);\n\n  const stopVoiceAnalysis = useCallback(() => {\n    if (recognitionRef.current) {\n      recognitionRef.current.stop();\n    }\n    \n    if (audioContextRef.current) {\n      audioContextRef.current.close();\n    }\n    \n    setIsAnalyzing(false);\n  }, [monitorVolume]);\n\n  return {\n    startVoiceAnalysis,\n    stopVoiceAnalysis,\n    isAnalyzing,\n    voiceResults: results\n  };\n};\n"],"mappings":";AAAA,SAASA,QAAQ,EAAEC,MAAM,EAAEC,WAAW,QAAQ,OAAO;AACrD,SAASC,oBAAoB,QAAQ,kCAAkC;AAYvE,OAAO,MAAMC,gBAAgB,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACpC,MAAM,CAACC,WAAW,EAAEC,cAAc,CAAC,GAAGP,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACQ,OAAO,EAAEC,UAAU,CAAC,GAAGT,QAAQ,CAA8B,IAAI,CAAC;EACzE,MAAMU,eAAe,GAAGT,MAAM,CAAsB,IAAI,CAAC;EACzD,MAAMU,WAAW,GAAGV,MAAM,CAAsB,IAAI,CAAC;EACrD,MAAMW,aAAa,GAAGX,MAAM,CAAoC,IAAI,CAAC;EACrE,MAAMY,cAAc,GAAGZ,MAAM,CAA2B,IAAI,CAAC;EAE7D,MAAMa,kBAAkB,GAAGZ,WAAW,CAAC,MAAM;IAC3CK,cAAc,CAAC,IAAI,CAAC;;IAEpB;IACA,IAAI,yBAAyB,IAAIQ,MAAM,IAAI,mBAAmB,IAAIA,MAAM,EAAE;MACxE,MAAMC,iBAAiB,GAAGD,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB;MACpFJ,cAAc,CAACK,OAAO,GAAG,IAAIF,iBAAiB,CAAC,CAAC;MAEhDH,cAAc,CAACK,OAAO,CAACC,UAAU,GAAG,IAAI;MACxCN,cAAc,CAACK,OAAO,CAACE,cAAc,GAAG,IAAI;MAC5CP,cAAc,CAACK,OAAO,CAACG,IAAI,GAAG,OAAO;MAErC,IAAIC,UAAU,GAAG,EAAE;MACnB,IAAIC,SAAS,GAAG,CAAC;MACjB,IAAIC,eAAe,GAAG,CAAC;MACvB,MAAMC,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;MAE5Bd,cAAc,CAACK,OAAO,CAACU,QAAQ,GAAIC,KAA6B,IAAK;QACnE,KAAK,IAAIC,CAAC,GAAGD,KAAK,CAACE,WAAW,EAAED,CAAC,GAAGD,KAAK,CAACrB,OAAO,CAACwB,MAAM,EAAEF,CAAC,EAAE,EAAE;UAC7D,MAAMG,MAAM,GAAGJ,KAAK,CAACrB,OAAO,CAACsB,CAAC,CAAC;UAC/B,IAAIG,MAAM,CAACC,OAAO,EAAE;YAClBZ,UAAU,IAAIW,MAAM,CAAC,CAAC,CAAC,CAACX,UAAU;YAClC,MAAMa,KAAK,GAAGF,MAAM,CAAC,CAAC,CAAC,CAACX,UAAU,CAACc,KAAK,CAAC,GAAG,CAAC;YAC7Cb,SAAS,IAAIY,KAAK,CAACH,MAAM;;YAEzB;YACA,MAAMK,WAAW,GAAG,CAAC,IAAI,EAAE,IAAI,EAAE,MAAM,EAAE,UAAU,EAAE,IAAI,EAAE,MAAM,EAAE,UAAU,CAAC;YAC9E,MAAMC,kBAAkB,GAAGH,KAAK,CAACI,MAAM,CAAEC,IAAY,IACnDH,WAAW,CAACI,QAAQ,CAACD,IAAI,CAACE,WAAW,CAAC,CAAC,CAACC,OAAO,CAAC,QAAQ,EAAE,EAAE,CAAC,CAC/D,CAAC,CAACX,MAAM;YACRR,eAAe,IAAIc,kBAAkB;UACvC;QACF;MACF,CAAC;MAEDzB,cAAc,CAACK,OAAO,CAAC0B,KAAK,GAAG,YAAY;QACzC,MAAMC,QAAQ,GAAG,CAACnB,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,SAAS,IAAI,IAAI,CAAC,CAAC;;QAElD,IAAI;UACF;UACA,MAAMqB,aAAa,GAAG,IAAIC,IAAI,CAAC,CAAC,iBAAiB,CAAC,EAAE;YAAEC,IAAI,EAAE;UAAY,CAAC,CAAC;;UAE1E;UACA,MAAMC,eAAe,GAAG,MAAM9C,oBAAoB,CAAC+C,YAAY,CAACJ,aAAa,EAAExB,UAAU,CAAC;UAC1Fb,UAAU,CAACwC,eAAe,CAAC;QAC7B,CAAC,CAAC,OAAOE,KAAK,EAAE;UACdC,OAAO,CAACD,KAAK,CAAC,wBAAwB,EAAEA,KAAK,CAAC;UAC9C;UACA,MAAME,YAAY,GAAG9B,SAAS,IAAIsB,QAAQ,GAAG,EAAE,CAAC;UAChDpC,UAAU,CAAC;YACT4B,WAAW,EAAEb,eAAe;YAC5B6B,YAAY,EAAEC,IAAI,CAACC,KAAK,CAACF,YAAY,CAAC;YACtCG,MAAM,EAAE,EAAE;YACVC,OAAO,EAAE,EAAE;YACXnC,UAAU;YACVoC,SAAS,EAAE,SAAS;YACpBC,UAAU,EAAE;UACd,CAAC,CAAC;QACJ;QAEApD,cAAc,CAAC,KAAK,CAAC;MACvB,CAAC;MAEDM,cAAc,CAACK,OAAO,CAAC0C,KAAK,CAAC,CAAC;IAChC;;IAEA;IACAC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;MAAEC,KAAK,EAAE;IAAK,CAAC,CAAC,CACjDC,IAAI,CAACC,MAAM,IAAI;MACdxD,eAAe,CAACQ,OAAO,GAAG,IAAIiD,YAAY,CAAC,CAAC;MAC5CxD,WAAW,CAACO,OAAO,GAAGR,eAAe,CAACQ,OAAO,CAACkD,cAAc,CAAC,CAAC;MAC9DxD,aAAa,CAACM,OAAO,GAAGR,eAAe,CAACQ,OAAO,CAACmD,uBAAuB,CAACH,MAAM,CAAC;MAE/EtD,aAAa,CAACM,OAAO,CAACoD,OAAO,CAAC3D,WAAW,CAACO,OAAO,CAAC;MAClDP,WAAW,CAACO,OAAO,CAACqD,OAAO,GAAG,GAAG;;MAEjC;MACAC,aAAa,CAAC,CAAC;IACjB,CAAC,CAAC,CACDC,KAAK,CAACtB,KAAK,IAAI;MACdC,OAAO,CAACD,KAAK,CAAC,6BAA6B,EAAEA,KAAK,CAAC;IACrD,CAAC,CAAC;EACN,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMqB,aAAa,GAAGtE,WAAW,CAAC,MAAM;IACtC,IAAI,CAACS,WAAW,CAACO,OAAO,EAAE;IAE1B,MAAMwD,SAAS,GAAG,IAAIC,UAAU,CAAChE,WAAW,CAACO,OAAO,CAAC0D,iBAAiB,CAAC;IACvEjE,WAAW,CAACO,OAAO,CAAC2D,oBAAoB,CAACH,SAAS,CAAC;;IAEnD;IACA;;IAEAI,qBAAqB,CAACN,aAAa,CAAC;EACtC,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMO,iBAAiB,GAAG7E,WAAW,CAAC,MAAM;IAC1C,IAAIW,cAAc,CAACK,OAAO,EAAE;MAC1BL,cAAc,CAACK,OAAO,CAAC8D,IAAI,CAAC,CAAC;IAC/B;IAEA,IAAItE,eAAe,CAACQ,OAAO,EAAE;MAC3BR,eAAe,CAACQ,OAAO,CAAC+D,KAAK,CAAC,CAAC;IACjC;IAEA1E,cAAc,CAAC,KAAK,CAAC;EACvB,CAAC,EAAE,CAACiE,aAAa,CAAC,CAAC;EAEnB,OAAO;IACL1D,kBAAkB;IAClBiE,iBAAiB;IACjBzE,WAAW;IACX4E,YAAY,EAAE1E;EAChB,CAAC;AACH,CAAC;AAACH,EAAA,CA1HWD,gBAAgB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}