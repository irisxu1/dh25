{"ast":null,"code":"var _s = $RefreshSig$();\nimport { useState, useRef, useCallback } from 'react';\nexport const useFacialAnalysis = () => {\n  _s();\n  const [isAnalyzing, setIsAnalyzing] = useState(false);\n  const [results, setResults] = useState(null);\n  const canvasRef = useRef(null);\n  const animationRef = useRef(null);\n  const startFacialAnalysis = useCallback(videoElement => {\n    setIsAnalyzing(true);\n\n    // Create canvas for face detection\n    const canvas = document.createElement('canvas');\n    const ctx = canvas.getContext('2d');\n    canvasRef.current = canvas;\n    if (!ctx) return;\n\n    // let frameCount = 0;\n    // let eyeContactCount = 0;\n    // let smileCount = 0;\n    // let confidenceSum = 0;\n\n    const analyzeFrame = () => {\n      if (!videoElement || videoElement.readyState !== 4) {\n        animationRef.current = requestAnimationFrame(analyzeFrame);\n        return;\n      }\n\n      // Set canvas dimensions to match video\n      canvas.width = videoElement.videoWidth;\n      canvas.height = videoElement.videoHeight;\n\n      // Draw current video frame to canvas\n      ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);\n\n      // Get image data for analysis\n      // const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n\n      // Mock facial analysis - in a real implementation, you would use:\n      // - MediaPipe Face Mesh\n      // - TensorFlow.js face detection\n      // - or another computer vision library\n\n      // frameCount++;\n\n      // Simulate eye contact detection (looking at center of screen)\n      // const centerX = canvas.width / 2;\n      // const centerY = canvas.height / 2;\n\n      // Mock: assume good eye contact 70% of the time\n      // if (Math.random() > 0.3) {\n      //   eyeContactCount++;\n      // }\n\n      // Mock: simulate smile detection\n      // if (Math.random() > 0.6) {\n      //   smileCount++;\n      // }\n\n      // Mock: simulate confidence level\n      // confidenceSum += 75 + Math.random() * 20; // 75-95 range\n\n      // Continue analysis\n      animationRef.current = requestAnimationFrame(analyzeFrame);\n    };\n    analyzeFrame();\n  }, []);\n  const stopFacialAnalysis = useCallback(() => {\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n\n    // Calculate final results with default values if no frames were processed\n    const frameCount = 100; // Mock frame count\n    const eyeContactCount = 70; // Mock data\n    const smileCount = 45; // Mock data\n    const confidenceSum = 8200; // Mock data\n\n    const finalResults = {\n      eyeContact: Math.round(eyeContactCount / frameCount * 100),\n      smileFrequency: Math.round(smileCount / frameCount * 100),\n      confidence: Math.round(confidenceSum / frameCount),\n      headMovement: Math.round(Math.random() * 30 + 10) // Mock data\n    };\n    setResults(finalResults);\n    setIsAnalyzing(false);\n  }, []);\n  return {\n    startFacialAnalysis,\n    stopFacialAnalysis,\n    isAnalyzing,\n    facialResults: results\n  };\n};\n_s(useFacialAnalysis, \"yUYWL2HqbefoBZZs6uxTeMn1nlA=\");","map":{"version":3,"names":["useState","useRef","useCallback","useFacialAnalysis","_s","isAnalyzing","setIsAnalyzing","results","setResults","canvasRef","animationRef","startFacialAnalysis","videoElement","canvas","document","createElement","ctx","getContext","current","analyzeFrame","readyState","requestAnimationFrame","width","videoWidth","height","videoHeight","drawImage","stopFacialAnalysis","cancelAnimationFrame","frameCount","eyeContactCount","smileCount","confidenceSum","finalResults","eyeContact","Math","round","smileFrequency","confidence","headMovement","random","facialResults"],"sources":["/Users/irisxu/Documents/DubHacks2025/dubhacksmain/src/hooks/useFacialAnalysis.ts"],"sourcesContent":["import { useState, useRef, useCallback } from 'react';\n\ninterface FacialAnalysisResults {\n  eyeContact: number;\n  smileFrequency: number;\n  confidence: number;\n  headMovement: number;\n}\n\nexport const useFacialAnalysis = () => {\n  const [isAnalyzing, setIsAnalyzing] = useState(false);\n  const [results, setResults] = useState<FacialAnalysisResults | null>(null);\n  const canvasRef = useRef<HTMLCanvasElement | null>(null);\n  const animationRef = useRef<number | null>(null);\n\n  const startFacialAnalysis = useCallback((videoElement: HTMLVideoElement) => {\n    setIsAnalyzing(true);\n    \n    // Create canvas for face detection\n    const canvas = document.createElement('canvas');\n    const ctx = canvas.getContext('2d');\n    canvasRef.current = canvas;\n    \n    if (!ctx) return;\n\n    // let frameCount = 0;\n    // let eyeContactCount = 0;\n    // let smileCount = 0;\n    // let confidenceSum = 0;\n\n    const analyzeFrame = () => {\n      if (!videoElement || videoElement.readyState !== 4) {\n        animationRef.current = requestAnimationFrame(analyzeFrame);\n        return;\n      }\n\n      // Set canvas dimensions to match video\n      canvas.width = videoElement.videoWidth;\n      canvas.height = videoElement.videoHeight;\n      \n      // Draw current video frame to canvas\n      ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);\n      \n      // Get image data for analysis\n      // const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n      \n      // Mock facial analysis - in a real implementation, you would use:\n      // - MediaPipe Face Mesh\n      // - TensorFlow.js face detection\n      // - or another computer vision library\n      \n      // frameCount++;\n      \n      // Simulate eye contact detection (looking at center of screen)\n      // const centerX = canvas.width / 2;\n      // const centerY = canvas.height / 2;\n      \n      // Mock: assume good eye contact 70% of the time\n      // if (Math.random() > 0.3) {\n      //   eyeContactCount++;\n      // }\n      \n      // Mock: simulate smile detection\n      // if (Math.random() > 0.6) {\n      //   smileCount++;\n      // }\n      \n      // Mock: simulate confidence level\n      // confidenceSum += 75 + Math.random() * 20; // 75-95 range\n      \n      // Continue analysis\n      animationRef.current = requestAnimationFrame(analyzeFrame);\n    };\n\n    analyzeFrame();\n  }, []);\n\n  const stopFacialAnalysis = useCallback(() => {\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    \n    // Calculate final results with default values if no frames were processed\n    const frameCount = 100; // Mock frame count\n    const eyeContactCount = 70; // Mock data\n    const smileCount = 45; // Mock data\n    const confidenceSum = 8200; // Mock data\n    \n    const finalResults: FacialAnalysisResults = {\n      eyeContact: Math.round((eyeContactCount / frameCount) * 100),\n      smileFrequency: Math.round((smileCount / frameCount) * 100),\n      confidence: Math.round(confidenceSum / frameCount),\n      headMovement: Math.round(Math.random() * 30 + 10) // Mock data\n    };\n    \n    setResults(finalResults);\n    setIsAnalyzing(false);\n  }, []);\n\n  return {\n    startFacialAnalysis,\n    stopFacialAnalysis,\n    isAnalyzing,\n    facialResults: results\n  };\n};\n"],"mappings":";AAAA,SAASA,QAAQ,EAAEC,MAAM,EAAEC,WAAW,QAAQ,OAAO;AASrD,OAAO,MAAMC,iBAAiB,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACrC,MAAM,CAACC,WAAW,EAAEC,cAAc,CAAC,GAAGN,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACO,OAAO,EAAEC,UAAU,CAAC,GAAGR,QAAQ,CAA+B,IAAI,CAAC;EAC1E,MAAMS,SAAS,GAAGR,MAAM,CAA2B,IAAI,CAAC;EACxD,MAAMS,YAAY,GAAGT,MAAM,CAAgB,IAAI,CAAC;EAEhD,MAAMU,mBAAmB,GAAGT,WAAW,CAAEU,YAA8B,IAAK;IAC1EN,cAAc,CAAC,IAAI,CAAC;;IAEpB;IACA,MAAMO,MAAM,GAAGC,QAAQ,CAACC,aAAa,CAAC,QAAQ,CAAC;IAC/C,MAAMC,GAAG,GAAGH,MAAM,CAACI,UAAU,CAAC,IAAI,CAAC;IACnCR,SAAS,CAACS,OAAO,GAAGL,MAAM;IAE1B,IAAI,CAACG,GAAG,EAAE;;IAEV;IACA;IACA;IACA;;IAEA,MAAMG,YAAY,GAAGA,CAAA,KAAM;MACzB,IAAI,CAACP,YAAY,IAAIA,YAAY,CAACQ,UAAU,KAAK,CAAC,EAAE;QAClDV,YAAY,CAACQ,OAAO,GAAGG,qBAAqB,CAACF,YAAY,CAAC;QAC1D;MACF;;MAEA;MACAN,MAAM,CAACS,KAAK,GAAGV,YAAY,CAACW,UAAU;MACtCV,MAAM,CAACW,MAAM,GAAGZ,YAAY,CAACa,WAAW;;MAExC;MACAT,GAAG,CAACU,SAAS,CAACd,YAAY,EAAE,CAAC,EAAE,CAAC,EAAEC,MAAM,CAACS,KAAK,EAAET,MAAM,CAACW,MAAM,CAAC;;MAE9D;MACA;;MAEA;MACA;MACA;MACA;;MAEA;;MAEA;MACA;MACA;;MAEA;MACA;MACA;MACA;;MAEA;MACA;MACA;MACA;;MAEA;MACA;;MAEA;MACAd,YAAY,CAACQ,OAAO,GAAGG,qBAAqB,CAACF,YAAY,CAAC;IAC5D,CAAC;IAEDA,YAAY,CAAC,CAAC;EAChB,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMQ,kBAAkB,GAAGzB,WAAW,CAAC,MAAM;IAC3C,IAAIQ,YAAY,CAACQ,OAAO,EAAE;MACxBU,oBAAoB,CAAClB,YAAY,CAACQ,OAAO,CAAC;IAC5C;;IAEA;IACA,MAAMW,UAAU,GAAG,GAAG,CAAC,CAAC;IACxB,MAAMC,eAAe,GAAG,EAAE,CAAC,CAAC;IAC5B,MAAMC,UAAU,GAAG,EAAE,CAAC,CAAC;IACvB,MAAMC,aAAa,GAAG,IAAI,CAAC,CAAC;;IAE5B,MAAMC,YAAmC,GAAG;MAC1CC,UAAU,EAAEC,IAAI,CAACC,KAAK,CAAEN,eAAe,GAAGD,UAAU,GAAI,GAAG,CAAC;MAC5DQ,cAAc,EAAEF,IAAI,CAACC,KAAK,CAAEL,UAAU,GAAGF,UAAU,GAAI,GAAG,CAAC;MAC3DS,UAAU,EAAEH,IAAI,CAACC,KAAK,CAACJ,aAAa,GAAGH,UAAU,CAAC;MAClDU,YAAY,EAAEJ,IAAI,CAACC,KAAK,CAACD,IAAI,CAACK,MAAM,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,CAAC,CAAC;IACpD,CAAC;IAEDhC,UAAU,CAACyB,YAAY,CAAC;IACxB3B,cAAc,CAAC,KAAK,CAAC;EACvB,CAAC,EAAE,EAAE,CAAC;EAEN,OAAO;IACLK,mBAAmB;IACnBgB,kBAAkB;IAClBtB,WAAW;IACXoC,aAAa,EAAElC;EACjB,CAAC;AACH,CAAC;AAACH,EAAA,CAhGWD,iBAAiB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}